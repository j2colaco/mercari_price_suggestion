{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stems words to their root words and removes all characters that are not alphabets\n",
    "def stem_str_item_description(str):\n",
    "    ret_str = \"\"\n",
    "    for w in word_tokenize(str.lower()):\n",
    "        if w not in stop_words and w.isalpha() and len(w) > 1:\n",
    "            ret_str = ret_str + \" \" + ps.stem(w)\n",
    "    ret_str = re.sub(\"[^a-zA-Z]\", \" \", ret_str)\n",
    "    return ret_str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stems words to their root words and removes all characters that are not alphabets\n",
    "def clean_str_brand_name(str):\n",
    "    ret_str = \"\"\n",
    "    for w in str.lower():\n",
    "        if w.isalnum() and len(w) > 0:\n",
    "            ret_str = ret_str + w\n",
    "#     ret_str = re.sub(\"[^a-zA-Z]\", \"\", ret_str)\n",
    "    return ret_str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_category_name(row):\n",
    "    if pd.isnull(row['category_name'])== True:\n",
    "        if row['clean_brand_name'] in brand_cat_dict.keys():\n",
    "            return brand_cat_dict[row['clean_brand_name']]\n",
    "        else:\n",
    "            return \"No category name\"\n",
    "    else:\n",
    "        return row['category_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code copied from https://www.kaggle.com/marknagelberg/rmsle-function\n",
    "def rmsle(y_pred, y_test) : \n",
    "    assert len(y_test) == len(y_pred)\n",
    "    return np.sqrt(np.mean((np.log(1+y_pred) - np.log(1+y_test))**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the count of most frequent words give a dataframe\n",
    "def word_freq(df, col):\n",
    "    word_frequency = {}\n",
    "    word_frequency_lst = []\n",
    "    for index,row in df.iterrows(): \n",
    "        for w in list(set(row[col].split(' '))):\n",
    "            if w not in word_frequency:\n",
    "                word_frequency[w] = 1\n",
    "            else:\n",
    "                word_frequency[w] += 1\n",
    "\n",
    "    for key, value in word_frequency.items():\n",
    "        temp = [key, value]\n",
    "        word_frequency_lst.append(temp)\n",
    "    word_freq_df = pd.DataFrame(word_frequency_lst, columns=[\"unique_word\", 'frequency'])\n",
    "    word_freq_df = word_freq_df.sort_values(['frequency'], ascending=False)\n",
    "    return word_freq_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joashc/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1482535, 8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unclean_train_data = pd.read_table('/Users/joashc/Downloads/mercari-price-suggestion-challenge/train.tsv')\n",
    "unclean_train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Unwanted Columns and Duplicate Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "unclean_train_data_v2 = unclean_train_data.drop(columns='train_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1482486, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unclean_train_data_v3 = unclean_train_data_v2.drop_duplicates()\n",
    "unclean_train_data_v3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with Nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name                      0\n",
       "item_condition_id         0\n",
       "category_name          6327\n",
       "brand_name           632641\n",
       "price                     0\n",
       "shipping                  0\n",
       "item_description          4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unclean_train_data_v3.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Brand Name Nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of brands: 4808\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>count_rows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PINK</td>\n",
       "      <td>54088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nike</td>\n",
       "      <td>54043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Victoria's Secret</td>\n",
       "      <td>48035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LuLaRoe</td>\n",
       "      <td>31024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Apple</td>\n",
       "      <td>17322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               brand  count_rows\n",
       "0               PINK       54088\n",
       "1               Nike       54043\n",
       "2  Victoria's Secret       48035\n",
       "3            LuLaRoe       31024\n",
       "4              Apple       17322"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brand_value_counts = (pd.DataFrame(unclean_train_data_v3.brand_name.value_counts())\n",
    "    .reset_index()\n",
    "    .rename(columns={'index':'brand',\n",
    "                    'brand_name':'count_rows'}))\n",
    "\n",
    "print('Number of brands:', brand_value_counts.shape[0]-1)\n",
    "brand_value_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joashc/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "unclean_train_data_v3['brand_name'] = unclean_train_data_v3['brand_name'].fillna(\"nobrandname\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name                    0\n",
       "item_condition_id       0\n",
       "category_name        6327\n",
       "brand_name              0\n",
       "price                   0\n",
       "shipping                0\n",
       "item_description        4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unclean_train_data_v3.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Item Description Nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approx 2.698170505488753e-06 % of the dataset contains item_description that are null.\n",
      "\n",
      "I am not deleting these rows because if the test data contains nulls in the item_description, I want to impute those values.\n"
     ]
    }
   ],
   "source": [
    "print('Approx', unclean_train_data_v3.item_description.isnull().sum()/unclean_train_data_v3.shape[0], \n",
    "      '% of the dataset contains item_description that are null.')\n",
    "print()\n",
    "print('I am not deleting these rows because if the test data contains nulls in the item_description,',\n",
    "     'I want to impute those values.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique item descriptions: 1281426\n"
     ]
    }
   ],
   "source": [
    "print('Unique item descriptions:', unclean_train_data_v3.item_description.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No description yet</th>\n",
       "      <td>82489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New</th>\n",
       "      <td>4099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brand new</th>\n",
       "      <td>3058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Good condition</th>\n",
       "      <td>1274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Great condition</th>\n",
       "      <td>1158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    item_description\n",
       "No description yet             82489\n",
       "New                             4099\n",
       "Brand new                       3058\n",
       "Good condition                  1274\n",
       "Great condition                 1158"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(unclean_train_data_v3.item_description.value_counts()).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill null item descriptions with \"No description yet\" as there are 82489 items that currently do not have any descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joashc/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "unclean_train_data_v3['item_description'] = unclean_train_data_v3['item_description'].fillna('No description yet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name                    0\n",
       "item_condition_id       0\n",
       "category_name        6327\n",
       "brand_name              0\n",
       "price                   0\n",
       "shipping                0\n",
       "item_description        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unclean_train_data_v3.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### category_name nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approx 0.004 % of the dataset contains category_name that are null.\n",
      "\n",
      "I am not deleting these rows because if the test data contains nulls in the category_name, I want to impute those values.\n"
     ]
    }
   ],
   "source": [
    "print('Approx', round(unclean_train_data_v3.category_name.isnull().sum()/unclean_train_data_v3.shape[0], 3), \n",
    "      '% of the dataset contains category_name that are null.')\n",
    "print()\n",
    "print('I am not deleting these rows because if the test data contains nulls in the category_name,',\n",
    "     'I want to impute those values.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2676 null values for category_name that have an item_description and brand_name\n",
      "\n",
      "There are 194 null values for category_name that have an brand_name but NO item_description\n",
      "\n",
      "There are 3029 null values for category_name that have a item_description but NO brand_name\n",
      "\n",
      "There are 0 null values for category_name that have NO brand_name and NO item_description\n"
     ]
    }
   ],
   "source": [
    "print(\"There are\", \n",
    "     unclean_train_data_v3[(unclean_train_data_v3['item_description']!='No description yet') & \n",
    "                     (unclean_train_data_v3['brand_name']!='nobrandname') & \n",
    "                          (unclean_train_data_v3['category_name'].isnull()==True)].shape[0],\n",
    "     \"null values for category_name that have an item_description and brand_name\")\n",
    "print()\n",
    "print(\"There are\", \n",
    "     unclean_train_data_v3[(unclean_train_data_v3['item_description']=='No description yet') & \n",
    "                     (unclean_train_data_v3['brand_name']!='nobrandname') & \n",
    "                          (unclean_train_data_v3['category_name'].isnull()==True)].shape[0],\n",
    "     \"null values for category_name that have an brand_name but NO item_description\")\n",
    "print()\n",
    "print(\"There are\", \n",
    "     unclean_train_data_v3[(unclean_train_data_v3['item_description']!='No description yet') & \n",
    "                     (unclean_train_data_v3['brand_name']=='nobrandname') & \n",
    "                          (unclean_train_data_v3['category_name'].isnull()== True)].shape[0],\n",
    "     \"null values for category_name that have a item_description but NO brand_name\")\n",
    "print()\n",
    "print(\"There are\", \n",
    "     unclean_train_data_v3[(unclean_train_data_v3['item_description']=='No description yet') & \n",
    "                     (unclean_train_data_v3['brand_name']=='nobrandname') & \n",
    "                          (unclean_train_data_v3['category_name'].isnull()== True)].shape[0],\n",
    "     \"null values for category_name that have NO brand_name and NO item_description\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Women/Athletic Apparel/Pants, Tights, Leggings</th>\n",
       "      <td>60176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Women/Tops &amp; Blouses/T-Shirts</th>\n",
       "      <td>46380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beauty/Makeup/Face</th>\n",
       "      <td>34331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beauty/Makeup/Lips</th>\n",
       "      <td>29908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Electronics/Video Games &amp; Consoles/Games</th>\n",
       "      <td>26557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                category_name\n",
       "Women/Athletic Apparel/Pants, Tights, Leggings          60176\n",
       "Women/Tops & Blouses/T-Shirts                           46380\n",
       "Beauty/Makeup/Face                                      34331\n",
       "Beauty/Makeup/Lips                                      29908\n",
       "Electronics/Video Games & Consoles/Games                26557"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(unclean_train_data_v3.category_name.value_counts()).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5899 null values for category_name left!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joashc/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "unclean_train_data_v3['category_name'] = np.where((unclean_train_data_v3['item_description']=='No description yet') &\n",
    "                                                  (unclean_train_data_v3['brand_name']=='nobrandname') &\n",
    "                                                   (unclean_train_data_v3['category_name'].isnull()== True),\n",
    "                                                  \"No category\",\n",
    "                                                  unclean_train_data_v3['category_name']\n",
    ")\n",
    "\n",
    "print(unclean_train_data_v3['category_name'].isnull().sum(), 'null values for category_name left!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For imputing the rest of the nulls for category_name, I want to use the item_description and brand_name columns. I first have to clean these columns to deal with the rest of the nulls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Text Cleaning\n",
    "- brand_name\n",
    "    - Make everything lower case\n",
    "    - Take out spaces\n",
    "    - Take out special characters\n",
    "- item_description\n",
    "    - Make everything lower case\n",
    "    - Take out special characters and numeric characters\n",
    "    - Tokenize\n",
    "    - Removal of stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13min 29s, sys: 4.17 s, total: 13min 34s\n",
      "Wall time: 13min 57s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joashc/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "unclean_train_data_v3['stemmed_item_description'] = unclean_train_data_v3['item_description'].apply(\n",
    "    lambda x: stem_str_item_description(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace nulls after cleaning with default talenized value\n",
    "unclean_train_data_v3['stemmed_item_description'] = np.where(\n",
    "    unclean_train_data_v3['stemmed_item_description'].isnull()==True,\n",
    "'descript yet', unclean_train_data_v3['stemmed_item_description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get from decriptions\n",
    " - oz\n",
    " - number of items\n",
    " - size (S, M, L, XL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.82 s, sys: 47.8 ms, total: 2.87 s\n",
      "Wall time: 2.88 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "unclean_train_data_v3['clean_brand_name'] = unclean_train_data_v3['brand_name'].apply(\n",
    "    lambda x: clean_str_brand_name(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name                           0\n",
       "item_condition_id              0\n",
       "category_name               5899\n",
       "brand_name                     0\n",
       "price                          0\n",
       "shipping                       0\n",
       "item_description               0\n",
       "stemmed_item_description    3320\n",
       "clean_brand_name               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unclean_train_data_v3.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with category_name Nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "606 unique brand names with null category names\n"
     ]
    }
   ],
   "source": [
    "unique_brand_names_w_na_category = (list(unclean_train_data_v3[\n",
    "    (unclean_train_data_v3['category_name'].isnull()== True)].clean_brand_name.unique()))\n",
    "\n",
    "print(len(unique_brand_names_w_na_category), 'unique brand names with null category names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found most popular categories for 579 brand names. For the rest of the brand names where we could not find the most popular category, we will, impute no categpry for now.\n",
      "CPU times: user 51 s, sys: 144 ms, total: 51.1 s\n",
      "Wall time: 51.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "brand_cat_dict = {}\n",
    "for brand in unique_brand_names_w_na_category:\n",
    "    subset_brand_data = unclean_train_data_v3[(unclean_train_data_v3['clean_brand_name']==brand) & \n",
    "                                             (unclean_train_data_v3['category_name'].isnull()==False)]\n",
    "    if subset_brand_data.shape[0] > 1:\n",
    "        # can only perform value counts of shape of dataset is greater than 1\n",
    "        brand_cat_dict[brand] = pd.DataFrame(subset_brand_data.category_name.value_counts()).head(1).index[0]\n",
    "print('Found most popular categories for', len(brand_cat_dict), 'brand names.',\n",
    "     'For the rest of the brand names where we could not find the most popular category, we will,'\n",
    "     ' impute no categpry for now.')\n",
    "\n",
    "for brand in list(set(unique_brand_names_w_na_category) - set(brand_cat_dict.keys())):\n",
    "    brand_cat_dict[brand] = \"No category\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = unclean_train_data_v3[unclean_train_data_v3['category_name'].isnull()==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "unclean_train_data_v3['category_name'] = unclean_train_data_v3.apply(impute_category_name, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name                        0\n",
       "item_condition_id           0\n",
       "category_name               0\n",
       "brand_name                  0\n",
       "price                       0\n",
       "shipping                    0\n",
       "item_description            0\n",
       "stemmed_item_description    0\n",
       "clean_brand_name            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unclean_train_data_v3.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean category_name Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace / with a space\n",
    "unclean_train_data_v3['category_name'] = unclean_train_data_v3['category_name'].str.replace('/',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 48s, sys: 1.28 s, total: 3min 49s\n",
      "Wall time: 3min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "unclean_train_data_v3['clean_category_name'] = unclean_train_data_v3['category_name'].apply(\n",
    "    lambda x: stem_str_item_description(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unclean_train_data_v3['clean_category_name'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean name Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace / with a space\n",
    "unclean_train_data_v3['name'] = unclean_train_data_v3['name'].str.replace('/',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 31s, sys: 752 ms, total: 3min 32s\n",
      "Wall time: 3min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "unclean_train_data_v3['clean_item_name'] = unclean_train_data_v3['name'].apply(\n",
    "    lambda x: stem_str_item_description(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unclean_train_data_v3['clean_item_name'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unclean_train_data_v3.to_csv(\n",
    "#     '/Users/joashc/Downloads/mercari-price-suggestion-challenge/partially_clean_train_data.csv', \n",
    "#     index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1482486, 9)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unclean_train_data_v3 = pd.read_csv(\n",
    "    '/Users/joashc/Downloads/mercari-price-suggestion-challenge/partially_clean_train_data.csv')\n",
    "unclean_train_data_v3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## item_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_condition_count</th>\n",
       "      <th>item_condition_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>640501</td>\n",
       "      <td>0.432045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>432161</td>\n",
       "      <td>0.291511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>375478</td>\n",
       "      <td>0.253276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31962</td>\n",
       "      <td>0.021560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2384</td>\n",
       "      <td>0.001608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_condition_count  item_condition_percent\n",
       "1                640501                0.432045\n",
       "3                432161                0.291511\n",
       "2                375478                0.253276\n",
       "4                 31962                0.021560\n",
       "5                  2384                0.001608"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_condition = pd.concat([pd.DataFrame(unclean_train_data_v3.item_condition_id.value_counts()),\n",
    "           pd.DataFrame(unclean_train_data_v3.item_condition_id.value_counts(normalize=True))], \n",
    "          axis=1)\n",
    "\n",
    "item_condition.columns = ['item_condition_count', 'item_condition_percent']\n",
    "item_condition.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th colspan=\"4\" halign=\"left\">price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>26.488162</td>\n",
       "      <td>2009.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>27.563231</td>\n",
       "      <td>2004.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>26.540711</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>24.349212</td>\n",
       "      <td>1309.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>31.703859</td>\n",
       "      <td>522.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  item_condition_id price                          \n",
       "                      min median       mean     max\n",
       "0                 1   0.0   18.0  26.488162  2009.0\n",
       "1                 2   0.0   17.0  27.563231  2004.0\n",
       "2                 3   0.0   16.0  26.540711  2000.0\n",
       "3                 4   0.0   15.0  24.349212  1309.0\n",
       "4                 5   0.0   19.0  31.703859   522.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_condition_agg = (unclean_train_data_v3\n",
    "    .groupby('item_condition_id')\n",
    "    .agg({'price':['min', 'median', 'mean', 'max']})\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "item_condition_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This aggregation of item condition and the price does not really tell us much as the dataset contains difference categories of items like clothing, jewelery, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import winsound\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "import time\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #Reading in the file via csv library\n",
    "    filepath = 'C:\\\\Users\\\\Joash\\\\Desktop\\\\University Stuff\\\\4B uni stuff\\\\SYDE 522\\\\522 Project\\\\SMS_spam_or_ham' \\\n",
    "               '\\\\spam_result'\n",
    "    csvfile = open(filepath + '.csv', \"rt\", encoding=\"utf8\")\n",
    "    reader = csv.reader(csvfile)\n",
    "    sms_stemmed = []\n",
    "    classification = []\n",
    "    sms = []\n",
    "    for row in reader:\n",
    "        if len(row[2]) != 0:\n",
    "            sms_stemmed.append(row[2])\n",
    "            sms.append(row[1])\n",
    "            if row[0] == \"spam\":\n",
    "                classification.append(1)\n",
    "            elif row[0] == \"ham\":\n",
    "                classification.append(0)\n",
    "    sms_stemmed = sms_stemmed[1:]\n",
    "    sms = sms[1:]\n",
    "    print(len(sms_stemmed), len(classification))\n",
    "\n",
    "    print(len(sms_stemmed), len(classification))\n",
    "    # sms_pd = pd.DataFrame(sms_stemmed)\n",
    "    # sms_pd.to_csv('check.csv')\n",
    "    random_state = 2\n",
    "    pre_score = []\n",
    "    acc_score = []\n",
    "    scores = []\n",
    "    predicted_classes = []\n",
    "    test_pred = []\n",
    "\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(sms_stemmed, classification, test_size=0.30, random_state=random_state)\n",
    "\n",
    "    max_features = 1500\n",
    "    tfidf = TfidfVectorizer(max_features=max_features)\n",
    "    x_tfidf = tfidf.fit_transform(sms_stemmed).toarray()\n",
    "    classification = np.asarray(classification)\n",
    "    print(type(x_tfidf), x_tfidf.shape, classification.shape)\n",
    "\n",
    "    # split into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_tfidf, classification, test_size=0.30, random_state=random_state)\n",
    "    print(len(X_test), len(y_test))\n",
    "\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    count = 1\n",
    "\n",
    "    for train, validate in kfold.split(X_train, y_train):\n",
    "        print('This is', count, 'fold!')\n",
    "        model = Sequential()\n",
    "        model.add(Dense(60, input_shape=(max_features,)))\n",
    "        model.add(Activation('relu'))\n",
    "        # model.add(Dropout(0.2))\n",
    "        model.add(Dense(5))\n",
    "        model.add(Activation('relu'))\n",
    "        # model.add(Dropout(0.2))\n",
    "        model.add(Dense(1))\n",
    "        model.add(Activation('sigmoid'))\n",
    "        model.summary()\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "        model.fit(X_train[train], y_train[train], batch_size=64, epochs=10, verbose=1)\n",
    "\n",
    "        test_pred = model.predict(X_train[validate])\n",
    "        # print(test_pred)\n",
    "        predicted_classes = np.around(test_pred, decimals=0)\n",
    "        # Creating the Confusion Matrix\n",
    "        cm = confusion_matrix(y_train[validate], predicted_classes)\n",
    "        print(cm)\n",
    "        accuracy = (cm[0, 0] + cm[1, 1]) / X_train[validate].shape[0]\n",
    "        precision = cm[0, 0] / (cm[0, 0] + cm[1, 0])\n",
    "        print('The accuracy and precision of the model is:', round(accuracy, 3), 'and', round(precision, 3))\n",
    "        acc_score.append(accuracy)\n",
    "        pre_score.append(precision)\n",
    "        count += 1\n",
    "\n",
    "    print('Model accuracy is', round(sum(acc_score) / len(acc_score),3))\n",
    "    print('Model precision is', round(sum(pre_score) / len(pre_score),3))\n",
    "    t1 = time.time()\n",
    "    test_pred = model.predict(X_test)\n",
    "    predicted_classes = np.around(test_pred, decimals=0)\n",
    "    t2 = time.time()\n",
    "    print(t2 - t1)\n",
    "    cm = confusion_matrix(y_test, predicted_classes)\n",
    "    print(cm)\n",
    "    # accuracy = (cm[0, 0] + cm[1, 1]) / X_test.shape[0]\n",
    "    accuracy = accuracy_score(y_test, predicted_classes)\n",
    "    # precision = cm[0, 0] / (cm[0, 0] + cm[1, 0])\n",
    "    precision = precision_score(y_test, predicted_classes)\n",
    "    print('Test accuracy is', accuracy)\n",
    "    print('Test precision is', precision)\n",
    "\n",
    "    print(len(X_test), len(test_pred))\n",
    "    test_output = []\n",
    "    for i in range(0, len(X_test), 1):\n",
    "        test_output.append([X_te[i], y_test[i], predicted_classes[i][0]])\n",
    "\n",
    "    test_output_df = pd.DataFrame(test_output, columns=['sms_stemmed', 'Actual Classification', 'Predicted Classification'])\n",
    "    test_output_df.to_csv('output.csv', index=False)\n",
    "\n",
    "    frequency = 2500  # Set Frequency To 2500 Hertz\n",
    "    duration = 500  # Set Duration To 1000 ms == 1 second\n",
    "    winsound.Beep(frequency, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joashc/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "test_df['no_nulls_category_name'] = test_df.apply(lambda x: impute_category_name(x), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Things you can do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Replace / with a space\n",
    "- Get stuff out of the description of category (size, oz, etc)\n",
    "- standardizing the categories (Clothes, Jewelery, Other)\n",
    "- get gender for each item (men, women, child, both, other(animal))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
