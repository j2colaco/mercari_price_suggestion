{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "\n",
    "ps = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code copied from https://www.kaggle.com/marknagelberg/rmsle-function\n",
    "def rmsle(y_pred, y_test) : \n",
    "    assert len(y_test) == len(y_pred)\n",
    "    return np.sqrt(np.mean((np.log(1+y_pred) - np.log(1+y_test))**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the count of most frequent words give a dataframe\n",
    "def word_freq(df, col):\n",
    "    word_frequency = {}\n",
    "    word_frequency_lst = []\n",
    "    for index,row in df.iterrows(): \n",
    "        for w in list(set(row[col].split(' '))):\n",
    "            if w not in word_frequency:\n",
    "                word_frequency[w] = 1\n",
    "            else:\n",
    "                word_frequency[w] += 1\n",
    "\n",
    "    for key, value in word_frequency.items():\n",
    "        temp = [key, value]\n",
    "        word_frequency_lst.append(temp)\n",
    "    word_freq_df = pd.DataFrame(word_frequency_lst, columns=[\"unique_word\", 'frequency'])\n",
    "    word_freq_df = word_freq_df.sort_values(['frequency'], ascending=False)\n",
    "    return word_freq_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unclean_train_data_v3 = pd.read_csv(\n",
    "    '/Users/joashc/Downloads/mercari-price-suggestion-challenge/partially_clean_train_data.csv')\n",
    "unclean_train_data_v3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark Model\n",
    "- Randomly output prices based on the distribution of price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.482486e+06\n",
       "mean     2.673804e+01\n",
       "std      3.858658e+01\n",
       "min      0.000000e+00\n",
       "25%      1.000000e+01\n",
       "50%      1.700000e+01\n",
       "75%      2.900000e+01\n",
       "max      2.009000e+03\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# describing price\n",
    "unclean_train_data_v3.price.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.307451e+06\n",
       "mean     2.182643e+01\n",
       "std      1.397454e+01\n",
       "min      6.500000e+00\n",
       "25%      1.200000e+01\n",
       "50%      1.700000e+01\n",
       "75%      2.800000e+01\n",
       "max      7.400000e+01\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# describing price removing 0.05 and 0.95 percentiles\n",
    "unclean_train_data_v3[(unclean_train_data_v3['price']>unclean_train_data_v3['price'].quantile(0.05)) &\n",
    "                  (unclean_train_data_v3['price']<unclean_train_data_v3['price'].quantile(0.95))].price.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x127cbde48>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# histogram of price removing 0.05 and 0.95 percentiles\n",
    "unclean_train_data_v3[(unclean_train_data_v3['price']>unclean_train_data_v3['price'].quantile(0.05)) &\n",
    "                  (unclean_train_data_v3['price']<unclean_train_data_v3['price'].quantile(0.95))].price.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean and standard deviation are: 26.74 , 38.59\n"
     ]
    }
   ],
   "source": [
    "mean = unclean_train_data_v3.price.mean()\n",
    "std_dev = unclean_train_data_v3.price.std()\n",
    "print('The mean and standard deviation are:', round(mean,2), ',',round(std_dev,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88436\n",
      "21537\n",
      "5178\n",
      "1178\n",
      "291\n",
      "64\n",
      "15\n",
      "4\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "price_prediction = pd.DataFrame(\n",
    "    np.random.normal(mean, std_dev, unclean_train_data_v3.shape[0]), columns=['price_prediction'])\n",
    "\n",
    "# this while loop is to make sure there are no negative values for the price\n",
    "num_neg = 1\n",
    "while num_neg > 0:\n",
    "    price_prediction['price_prediction'] = price_prediction['price_prediction'].apply(\n",
    "        lambda x: np.random.normal(mean, std_dev, 1)[0] if x<=0 else x)\n",
    "\n",
    "    num_neg = price_prediction[price_prediction['price_prediction']<=0].shape[0]\n",
    "    print(num_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of normal distrubition benchmark model is: 50.49\n",
      "\n",
      "RMSLE of normal distrubition benchmark model is: 1.26\n"
     ]
    }
   ],
   "source": [
    "print('RMSE of normal distrubition benchmark model is:', \n",
    "      round(np.sqrt(mean_squared_error(unclean_train_data_v3['price'],price_prediction['price_prediction'])), 2))\n",
    "\n",
    "print()\n",
    "\n",
    "print('RMSLE of normal distrubition benchmark model is:',\n",
    "      round(rmsle(unclean_train_data_v3['price'],price_prediction['price_prediction']),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean and standard deviation are: 21.83 , 13.97\n"
     ]
    }
   ],
   "source": [
    "mean = unclean_train_data_v3[(unclean_train_data_v3['price']>unclean_train_data_v3['price'].quantile(0.05)) &\n",
    "                  (unclean_train_data_v3['price']<unclean_train_data_v3['price'].quantile(0.95))].price.mean()\n",
    "std_dev = unclean_train_data_v3[(unclean_train_data_v3['price']>unclean_train_data_v3['price'].quantile(0.05)) &\n",
    "                  (unclean_train_data_v3['price']<unclean_train_data_v3['price'].quantile(0.95))].price.std()\n",
    "print('The mean and standard deviation are:', round(mean,2), ',',round(std_dev,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5201\n",
      "313\n",
      "20\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "price_prediction = pd.DataFrame(\n",
    "    np.random.normal(mean, std_dev, unclean_train_data_v3.shape[0]), columns=['price_prediction'])\n",
    "\n",
    "# this while loop is to make sure there are no negative values for the price\n",
    "num_neg = 1\n",
    "while num_neg > 0:\n",
    "    price_prediction['price_prediction'] = price_prediction['price_prediction'].apply(\n",
    "        lambda x: np.random.normal(mean, std_dev, 1)[0] if x<=0 else x)\n",
    "\n",
    "    num_neg = price_prediction[price_prediction['price_prediction']<=0].shape[0]\n",
    "    print(num_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of normal distrubition benchmark model is: 40.65\n",
      "\n",
      "RMSLE of normal distrubition benchmark model is: 1.01\n"
     ]
    }
   ],
   "source": [
    "print('RMSE of normal distrubition benchmark model is:', \n",
    "      round(np.sqrt(mean_squared_error(unclean_train_data_v3['price'],price_prediction['price_prediction'])), 2))\n",
    "\n",
    "print()\n",
    "\n",
    "print('RMSLE of normal distrubition benchmark model is:',\n",
    "      round(rmsle(unclean_train_data_v3['price'],price_prediction['price_prediction']),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The median and standard deviation are: 21.83 , 13.97\n"
     ]
    }
   ],
   "source": [
    "median = unclean_train_data_v3[(unclean_train_data_v3['price']>unclean_train_data_v3['price'].quantile(0.05)) &\n",
    "                  (unclean_train_data_v3['price']<unclean_train_data_v3['price'].quantile(0.95))].price.median()\n",
    "std_dev = unclean_train_data_v3[(unclean_train_data_v3['price']>unclean_train_data_v3['price'].quantile(0.05)) &\n",
    "                  (unclean_train_data_v3['price']<unclean_train_data_v3['price'].quantile(0.95))].price.std()\n",
    "print('The median and standard deviation are:', round(mean,2), ',',round(std_dev,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18573\n",
      "2134\n",
      "260\n",
      "18\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "price_prediction = pd.DataFrame(\n",
    "    np.random.normal(median, std_dev, unclean_train_data_v3.shape[0]), columns=['price_prediction'])\n",
    "\n",
    "# this while loop is to make sure there are no negative values for the price\n",
    "num_neg = 1\n",
    "while num_neg > 0:\n",
    "    price_prediction['price_prediction'] = price_prediction['price_prediction'].apply(\n",
    "        lambda x: np.random.normal(median, std_dev, 1)[0] if x<=0 else x)\n",
    "\n",
    "    num_neg = price_prediction[price_prediction['price_prediction']<=0].shape[0]\n",
    "    print(num_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of normal distrubition benchmark model is: 40.87\n",
      "\n",
      "RMSLE of normal distrubition benchmark model is: 1.05\n"
     ]
    }
   ],
   "source": [
    "print('RMSE of normal distrubition benchmark model is:', \n",
    "      round(np.sqrt(mean_squared_error(unclean_train_data_v3['price'],price_prediction['price_prediction'])), 2))\n",
    "\n",
    "print()\n",
    "\n",
    "print('RMSLE of normal distrubition benchmark model is:',\n",
    "      round(rmsle(unclean_train_data_v3['price'],price_prediction['price_prediction']),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling Text\n",
    "- stemmed_item_description\n",
    "    - tdidf matrix\n",
    "- clean_brand_name\n",
    "    - One-hot-encode\n",
    "- clean_category_name\n",
    "    - One-hot-encode unique values if possible\n",
    "- clean_item_name\n",
    "    - tdidf matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot-encoding Brand Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 143 brand names that occur >= 1000 times in the dataset. Will one-hot-encode these brands only.\n"
     ]
    }
   ],
   "source": [
    "unique_brand_names = pd.DataFrame(unclean_train_data_v3.clean_brand_name.value_counts())\n",
    "min_brand_freq = 1000\n",
    "print('There are', unique_brand_names[unique_brand_names['clean_brand_name']>=min_brand_freq].shape[0],\n",
    "      'brand names that occur >=',min_brand_freq, 'times in the dataset.','Will one-hot-encode these brands only.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1482486,)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_brand_name_df = unclean_train_data_v3['clean_brand_name']\n",
    "clean_brand_name_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_brand_name_df = pd.get_dummies(clean_brand_name_df)\n",
    "clean_brand_name_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_brand_col_lst = []\n",
    "keep_brand_col_lst = list(unique_brand_names[unique_brand_names['clean_brand_name']>=min_brand_freq].index.values)\n",
    "\n",
    "for col_name in clean_brand_name_df.columns:\n",
    "    if col_name not in keep_brand_col_lst:\n",
    "        drop_brand_col_lst.append(col_name)\n",
    "\n",
    "clean_brand_name_df_v2 =clean_brand_name_df.drop(columns=drop_brand_col_lst)\n",
    "clean_brand_name_df_v2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1482486, 152)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unclean_train_data_v4 = pd.concat([unclean_train_data_v3, clean_brand_name_df_v2], axis=1).drop(columns=\n",
    "                                                                                            ['brand_name', \n",
    "                                                                                            'clean_brand_name'])\n",
    "unclean_train_data_v4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot-encoding Category Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1482486, 1)"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_category_name_df = unclean_train_data_v4[['clean_category_name']]\n",
    "# taking out duplicate categories\n",
    "clean_category_name_df_v2 = clean_category_name_df.copy()\n",
    "clean_category_name_df_v2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words in the category name columns is: 838\n",
      "CPU times: user 1min 49s, sys: 129 ms, total: 1min 49s\n",
      "Wall time: 1min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "category_name_word_freq = word_freq(clean_category_name_df_v2, 'clean_category_name')\n",
    "print('Number of unique words in the category name columns is:', category_name_word_freq.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 92 unique words that occur more than 10000 times in the clean_category_name columns. Will one-hot-encode these frequent unique words.\n"
     ]
    }
   ],
   "source": [
    "min_category_freq = 10000\n",
    "print('There are', category_name_word_freq[category_name_word_freq['frequency']>min_category_freq].shape[0],\n",
    "      'unique words that occur more than', min_category_freq, 'times in the clean_category_name columns.', \n",
    "      'Will one-hot-encode these frequent unique words.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_cat_name_lst = list(category_name_word_freq[category_name_word_freq['frequency']>10000].unique_word.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique clean_category_name: 1255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joashc/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:362: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/Users/joashc/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 4s, sys: 519 ms, total: 2min 4s\n",
      "Wall time: 2min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clean_category_name_df_v3 = clean_category_name_df.drop_duplicates()\n",
    "print('Number of unique clean_category_name:', clean_category_name_df_v3.shape[0])\n",
    "for index, row in clean_category_name_df_v3.iterrows():\n",
    "    for unique_cat_word in unique_cat_name_lst:\n",
    "        if unique_cat_word in row['clean_category_name'].split(' '):\n",
    "            clean_category_name_df_v3.loc[index, 'category_' + str(unique_cat_word)] = 1\n",
    "\n",
    "clean_category_name_df_v3 = clean_category_name_df_v3.fillna(0)\n",
    "clean_category_name_df_v3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1482486, 152)\n",
      "(1482486, 242)\n"
     ]
    }
   ],
   "source": [
    "# merge with main dataset on clean_category_name\n",
    "print(unclean_train_data_v4.shape)\n",
    "unclean_train_data_v5 = (unclean_train_data_v4\n",
    "                         .merge(clean_category_name_df_v3, on='clean_category_name', how='left')\n",
    "                         .drop(columns=['category_name', 'clean_category_name']))\n",
    "print(unclean_train_data_v5.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF item_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1482486,)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_description_df = unclean_train_data_v5['stemmed_item_description']\n",
    "item_description_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1482486, 100)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_desc_0</th>\n",
       "      <th>item_desc_1</th>\n",
       "      <th>item_desc_2</th>\n",
       "      <th>item_desc_3</th>\n",
       "      <th>item_desc_4</th>\n",
       "      <th>item_desc_5</th>\n",
       "      <th>item_desc_6</th>\n",
       "      <th>item_desc_7</th>\n",
       "      <th>item_desc_8</th>\n",
       "      <th>item_desc_9</th>\n",
       "      <th>...</th>\n",
       "      <th>item_desc_90</th>\n",
       "      <th>item_desc_91</th>\n",
       "      <th>item_desc_92</th>\n",
       "      <th>item_desc_93</th>\n",
       "      <th>item_desc_94</th>\n",
       "      <th>item_desc_95</th>\n",
       "      <th>item_desc_96</th>\n",
       "      <th>item_desc_97</th>\n",
       "      <th>item_desc_98</th>\n",
       "      <th>item_desc_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.714017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.312713</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.734306</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_desc_0  item_desc_1  item_desc_2  item_desc_3  item_desc_4  \\\n",
       "0          0.0          0.0          0.0          0.0          0.0   \n",
       "1          0.0          0.0          0.0          0.0          0.0   \n",
       "\n",
       "   item_desc_5  item_desc_6  item_desc_7  item_desc_8  item_desc_9  ...  \\\n",
       "0          0.0          0.0          0.0          0.0     0.000000  ...   \n",
       "1          0.0          0.0          0.0          0.0     0.312713  ...   \n",
       "\n",
       "   item_desc_90  item_desc_91  item_desc_92  item_desc_93  item_desc_94  \\\n",
       "0           0.0           0.0           0.0           0.0           0.0   \n",
       "1           0.0           0.0           0.0           0.0           0.0   \n",
       "\n",
       "   item_desc_95  item_desc_96  item_desc_97  item_desc_98  item_desc_99  \n",
       "0           0.0           0.0      0.000000           0.0      0.714017  \n",
       "1           0.0           0.0      0.734306           0.0      0.000000  \n",
       "\n",
       "[2 rows x 100 columns]"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_features = 100\n",
    "tfidf = TfidfVectorizer(max_features=max_features)\n",
    "x_tfidf = pd.DataFrame(tfidf.fit_transform(item_description_df).toarray())\n",
    "x_tfidf.columns = ['item_desc_' + str(col) for col in x_tfidf.columns]\n",
    "print(x_tfidf.shape)\n",
    "x_tfidf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1482486, 242)\n",
      "(1482486, 340)\n"
     ]
    }
   ],
   "source": [
    "print(unclean_train_data_v5.shape)\n",
    "unclean_train_data_v6 = pd.concat([unclean_train_data_v5, x_tfidf], axis=1).drop(columns=['item_description', \n",
    "                                                                                         'stemmed_item_description'])\n",
    "print(unclean_train_data_v6.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF clean_item_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1482486,)"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_name_df = unclean_train_data_v5['clean_item_name']\n",
    "item_name_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1482486, 100)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_name_item_desc_0</th>\n",
       "      <th>item_name_item_desc_1</th>\n",
       "      <th>item_name_item_desc_2</th>\n",
       "      <th>item_name_item_desc_3</th>\n",
       "      <th>item_name_item_desc_4</th>\n",
       "      <th>item_name_item_desc_5</th>\n",
       "      <th>item_name_item_desc_6</th>\n",
       "      <th>item_name_item_desc_7</th>\n",
       "      <th>item_name_item_desc_8</th>\n",
       "      <th>item_name_item_desc_9</th>\n",
       "      <th>...</th>\n",
       "      <th>item_name_item_desc_90</th>\n",
       "      <th>item_name_item_desc_91</th>\n",
       "      <th>item_name_item_desc_92</th>\n",
       "      <th>item_name_item_desc_93</th>\n",
       "      <th>item_name_item_desc_94</th>\n",
       "      <th>item_name_item_desc_95</th>\n",
       "      <th>item_name_item_desc_96</th>\n",
       "      <th>item_name_item_desc_97</th>\n",
       "      <th>item_name_item_desc_98</th>\n",
       "      <th>item_name_item_desc_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.554055</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_name_item_desc_0  item_name_item_desc_1  item_name_item_desc_2  \\\n",
       "0                    0.0                    0.0                    0.0   \n",
       "1                    0.0                    0.0                    0.0   \n",
       "\n",
       "   item_name_item_desc_3  item_name_item_desc_4  item_name_item_desc_5  \\\n",
       "0                    0.0                    0.0                    0.0   \n",
       "1                    0.0                    0.0                    0.0   \n",
       "\n",
       "   item_name_item_desc_6  item_name_item_desc_7  item_name_item_desc_8  \\\n",
       "0                    0.0                    0.0                    0.0   \n",
       "1                    0.0                    0.0                    0.0   \n",
       "\n",
       "   item_name_item_desc_9  ...  item_name_item_desc_90  item_name_item_desc_91  \\\n",
       "0                    0.0  ...                     0.0                     0.0   \n",
       "1                    0.0  ...                     0.0                     0.0   \n",
       "\n",
       "   item_name_item_desc_92  item_name_item_desc_93  item_name_item_desc_94  \\\n",
       "0                     0.0                     0.0                     0.0   \n",
       "1                     0.0                     0.0                     0.0   \n",
       "\n",
       "   item_name_item_desc_95  item_name_item_desc_96  item_name_item_desc_97  \\\n",
       "0                     0.0                     0.0                     0.0   \n",
       "1                     0.0                     0.0                     0.0   \n",
       "\n",
       "   item_name_item_desc_98  item_name_item_desc_99  \n",
       "0                0.554055                     0.0  \n",
       "1                0.000000                     0.0  \n",
       "\n",
       "[2 rows x 100 columns]"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_features_2 = 100\n",
    "tfidf = TfidfVectorizer(max_features=max_features_2)\n",
    "item_name_tfidf = pd.DataFrame(tfidf.fit_transform(item_name_df).toarray())\n",
    "item_name_tfidf.columns = ['item_name_' + str(col) for col in x_tfidf.columns]\n",
    "print(item_name_tfidf.shape)\n",
    "item_name_tfidf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1482486, 340)\n",
      "(1482486, 438)\n"
     ]
    }
   ],
   "source": [
    "print(unclean_train_data_v6.shape)\n",
    "unclean_train_data_v7 = pd.concat([unclean_train_data_v6, item_name_tfidf], axis=1).drop(columns=['clean_item_name', \n",
    "                                                                                         'name'])\n",
    "print(unclean_train_data_v7.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unclean_train_data_v7.to_csv(\n",
    "#     '/Users/joashc/Downloads/mercari-price-suggestion-challenge/inputs_for_model.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1482486, 438)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepped_data = pd.read_csv(\n",
    "    '/Users/joashc/Downloads/mercari-price-suggestion-challenge/inputs_for_model.csv')\n",
    "prepped_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating features from labels\n",
    "X = prepped_data.drop(columns=['price'])\n",
    "y = prepped_data[['price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in train and validation data: 1185988\n",
      "Number of rows in test data: 296498\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = train_test_split(X.reset_index(drop=True), \n",
    "                                                    y.reset_index(drop=True), \n",
    "                                                                  test_size=0.2, random_state=42)\n",
    "print('Number of rows in train and validation data:', X_train.shape[0])\n",
    "print('Number of rows in test data:', y_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "count = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1185988, 296498]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-7c01f0b9cdbc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkfold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mtesting\u001b[0m \u001b[0mset\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthat\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \"\"\"\n\u001b[0;32m--> 323\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 235\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1185988, 296498]"
     ]
    }
   ],
   "source": [
    "for i,j in kfold.split(X_train, y_train):\n",
    "    print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1185988, 296498]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-b9ef85aeb615>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkfold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'This is'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fold!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mtesting\u001b[0m \u001b[0mset\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthat\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \"\"\"\n\u001b[0;32m--> 323\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 235\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1185988, 296498]"
     ]
    }
   ],
   "source": [
    "for train, validate in kfold.split(X_train, y_train):\n",
    "#     print('This is', count, 'fold!')\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(60, input_shape=(max_features,)))\n",
    "#     model.add(Activation('relu'))\n",
    "#     # model.add(Dropout(0.2))\n",
    "#     model.add(Dense(5))\n",
    "#     model.add(Activation('relu'))\n",
    "#     # model.add(Dropout(0.2))\n",
    "#     model.add(Dense(1))\n",
    "#     model.add(Activation('sigmoid'))\n",
    "#     model.summary()\n",
    "#     model.compile(loss='mean_squared_logarithmic_error', optimizer='adam', metrics=['acc'])\n",
    "#     model.fit(X_train[train], y_train[train], batch_size=64, epochs=10, verbose=1)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hidden layer 1: 32 neurons, ReLU activation\n",
    "Hidden layer 2: 32 neurons, ReLU activation\n",
    "Output Layer: 1 neuron, Sigmoid activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model architecture parameters\n",
    "n_stocks = 500\n",
    "n_neurons_1 = 1024\n",
    "n_neurons_2 = 512\n",
    "n_neurons_3 = 256\n",
    "n_neurons_4 = 128\n",
    "n_target = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import winsound\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "import time\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #Reading in the file via csv library\n",
    "    filepath = 'C:\\\\Users\\\\Joash\\\\Desktop\\\\University Stuff\\\\4B uni stuff\\\\SYDE 522\\\\522 Project\\\\SMS_spam_or_ham' \\\n",
    "               '\\\\spam_result'\n",
    "    csvfile = open(filepath + '.csv', \"rt\", encoding=\"utf8\")\n",
    "    reader = csv.reader(csvfile)\n",
    "    sms_stemmed = []\n",
    "    classification = []\n",
    "    sms = []\n",
    "    for row in reader:\n",
    "        if len(row[2]) != 0:\n",
    "            sms_stemmed.append(row[2])\n",
    "            sms.append(row[1])\n",
    "            if row[0] == \"spam\":\n",
    "                classification.append(1)\n",
    "            elif row[0] == \"ham\":\n",
    "                classification.append(0)\n",
    "    sms_stemmed = sms_stemmed[1:]\n",
    "    sms = sms[1:]\n",
    "    print(len(sms_stemmed), len(classification))\n",
    "\n",
    "    print(len(sms_stemmed), len(classification))\n",
    "    # sms_pd = pd.DataFrame(sms_stemmed)\n",
    "    # sms_pd.to_csv('check.csv')\n",
    "    random_state = 2\n",
    "    pre_score = []\n",
    "    acc_score = []\n",
    "    scores = []\n",
    "    predicted_classes = []\n",
    "    test_pred = []\n",
    "\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(sms_stemmed, classification, test_size=0.30, random_state=random_state)\n",
    "\n",
    "    max_features = 1500\n",
    "    tfidf = TfidfVectorizer(max_features=max_features)\n",
    "    x_tfidf = tfidf.fit_transform(sms_stemmed).toarray()\n",
    "    classification = np.asarray(classification)\n",
    "    print(type(x_tfidf), x_tfidf.shape, classification.shape)\n",
    "\n",
    "    # split into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_tfidf, classification, test_size=0.30, random_state=random_state)\n",
    "    print(len(X_test), len(y_test))\n",
    "\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    count = 1\n",
    "\n",
    "    for train, validate in kfold.split(X_train, y_train):\n",
    "        print('This is', count, 'fold!')\n",
    "        model = Sequential()\n",
    "        model.add(Dense(60, input_shape=(max_features,)))\n",
    "        model.add(Activation('relu'))\n",
    "        # model.add(Dropout(0.2))\n",
    "        model.add(Dense(5))\n",
    "        model.add(Activation('relu'))\n",
    "        # model.add(Dropout(0.2))\n",
    "        model.add(Dense(1))\n",
    "        model.add(Activation('sigmoid'))\n",
    "        model.summary()\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "        model.fit(X_train[train], y_train[train], batch_size=64, epochs=10, verbose=1)\n",
    "\n",
    "        test_pred = model.predict(X_train[validate])\n",
    "        # print(test_pred)\n",
    "        predicted_classes = np.around(test_pred, decimals=0)\n",
    "        # Creating the Confusion Matrix\n",
    "        cm = confusion_matrix(y_train[validate], predicted_classes)\n",
    "        print(cm)\n",
    "        accuracy = (cm[0, 0] + cm[1, 1]) / X_train[validate].shape[0]\n",
    "        precision = cm[0, 0] / (cm[0, 0] + cm[1, 0])\n",
    "        print('The accuracy and precision of the model is:', round(accuracy, 3), 'and', round(precision, 3))\n",
    "        acc_score.append(accuracy)\n",
    "        pre_score.append(precision)\n",
    "        count += 1\n",
    "\n",
    "    print('Model accuracy is', round(sum(acc_score) / len(acc_score),3))\n",
    "    print('Model precision is', round(sum(pre_score) / len(pre_score),3))\n",
    "    t1 = time.time()\n",
    "    test_pred = model.predict(X_test)\n",
    "    predicted_classes = np.around(test_pred, decimals=0)\n",
    "    t2 = time.time()\n",
    "    print(t2 - t1)\n",
    "    cm = confusion_matrix(y_test, predicted_classes)\n",
    "    print(cm)\n",
    "    # accuracy = (cm[0, 0] + cm[1, 1]) / X_test.shape[0]\n",
    "    accuracy = accuracy_score(y_test, predicted_classes)\n",
    "    # precision = cm[0, 0] / (cm[0, 0] + cm[1, 0])\n",
    "    precision = precision_score(y_test, predicted_classes)\n",
    "    print('Test accuracy is', accuracy)\n",
    "    print('Test precision is', precision)\n",
    "\n",
    "    print(len(X_test), len(test_pred))\n",
    "    test_output = []\n",
    "    for i in range(0, len(X_test), 1):\n",
    "        test_output.append([X_te[i], y_test[i], predicted_classes[i][0]])\n",
    "\n",
    "    test_output_df = pd.DataFrame(test_output, columns=['sms_stemmed', 'Actual Classification', 'Predicted Classification'])\n",
    "    test_output_df.to_csv('output.csv', index=False)\n",
    "\n",
    "    frequency = 2500  # Set Frequency To 2500 Hertz\n",
    "    duration = 500  # Set Duration To 1000 ms == 1 second\n",
    "    winsound.Beep(frequency, duration)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
