{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joashc/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code copied from https://www.kaggle.com/marknagelberg/rmsle-function\n",
    "def rmsle(y_pred, y_test) : \n",
    "    assert len(y_test) == len(y_pred)\n",
    "    return np.sqrt(np.mean((np.log(1+y_pred) - np.log(1+y_test))**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the count of most frequent words give a dataframe\n",
    "def word_freq(df, col):\n",
    "    word_frequency = {}\n",
    "    word_frequency_lst = []\n",
    "    for index,row in df.iterrows(): \n",
    "        for w in list(set(str(row[col]).split(' '))):\n",
    "            if w not in word_frequency:\n",
    "                word_frequency[w] = 1\n",
    "            else:\n",
    "                word_frequency[w] += 1\n",
    "\n",
    "    for key, value in word_frequency.items():\n",
    "        temp = [key, value]\n",
    "        word_frequency_lst.append(temp)\n",
    "    word_freq_df = pd.DataFrame(word_frequency_lst, columns=[\"unique_word\", 'frequency'])\n",
    "    word_freq_df = word_freq_df.sort_values(['frequency'], ascending=False)\n",
    "    return word_freq_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1482486, 13)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data = pd.read_csv(\n",
    "    '/Users/joashc/Downloads/mercari-price-suggestion-challenge/partially_clean_train_data.csv')\n",
    "clean_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "      <th>stemmed_item_description</th>\n",
       "      <th>clean_brand_name</th>\n",
       "      <th>clean_category_name</th>\n",
       "      <th>clean_item_name</th>\n",
       "      <th>assigned_category</th>\n",
       "      <th>assigned_sub_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLB Cincinnati Reds T Shirt Size XL</td>\n",
       "      <td>3</td>\n",
       "      <td>Men Tops T-shirts</td>\n",
       "      <td>nobrandname</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>No description yet</td>\n",
       "      <td>descript yet</td>\n",
       "      <td>nobrandname</td>\n",
       "      <td>men top</td>\n",
       "      <td>mlb cincinnati red shirt size xl</td>\n",
       "      <td>Men</td>\n",
       "      <td>Tops</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Razer BlackWidow Chroma Keyboard</td>\n",
       "      <td>3</td>\n",
       "      <td>Electronics Computers &amp; Tablets Components &amp; P...</td>\n",
       "      <td>Razer</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>This keyboard is in great condition and works ...</td>\n",
       "      <td>keyboard great condit work like came box port ...</td>\n",
       "      <td>razer</td>\n",
       "      <td>electron comput tablet compon part</td>\n",
       "      <td>razer blackwidow chroma keyboard</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AVA-VIV Blouse</td>\n",
       "      <td>1</td>\n",
       "      <td>Women Tops &amp; Blouses Blouse</td>\n",
       "      <td>Target</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Adorable top with a hint of lace and a key hol...</td>\n",
       "      <td>ador top hint lace key hole back pale pink als...</td>\n",
       "      <td>target</td>\n",
       "      <td>women top blous blous</td>\n",
       "      <td>blous</td>\n",
       "      <td>Women</td>\n",
       "      <td>Tops &amp; blouses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Leather Horse Statues</td>\n",
       "      <td>1</td>\n",
       "      <td>Home Home Décor Home Décor Accents</td>\n",
       "      <td>nobrandname</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>New with tags. Leather horses. Retail for [rm]...</td>\n",
       "      <td>new tag leather hors retail rm stand foot high...</td>\n",
       "      <td>nobrandname</td>\n",
       "      <td>home home d cor home d cor accent</td>\n",
       "      <td>leather hors statu</td>\n",
       "      <td>Home</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24K GOLD plated rose</td>\n",
       "      <td>1</td>\n",
       "      <td>Women Jewelry Necklaces</td>\n",
       "      <td>nobrandname</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Complete with certificate of authenticity</td>\n",
       "      <td>complet certif authent</td>\n",
       "      <td>nobrandname</td>\n",
       "      <td>women jewelri necklac</td>\n",
       "      <td>gold plate rose</td>\n",
       "      <td>Women</td>\n",
       "      <td>Jewelry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  name  item_condition_id  \\\n",
       "0  MLB Cincinnati Reds T Shirt Size XL                  3   \n",
       "1     Razer BlackWidow Chroma Keyboard                  3   \n",
       "2                       AVA-VIV Blouse                  1   \n",
       "3                Leather Horse Statues                  1   \n",
       "4                 24K GOLD plated rose                  1   \n",
       "\n",
       "                                       category_name   brand_name  price  \\\n",
       "0                                  Men Tops T-shirts  nobrandname   10.0   \n",
       "1  Electronics Computers & Tablets Components & P...        Razer   52.0   \n",
       "2                        Women Tops & Blouses Blouse       Target   10.0   \n",
       "3                 Home Home Décor Home Décor Accents  nobrandname   35.0   \n",
       "4                            Women Jewelry Necklaces  nobrandname   44.0   \n",
       "\n",
       "   shipping                                   item_description  \\\n",
       "0         1                                 No description yet   \n",
       "1         0  This keyboard is in great condition and works ...   \n",
       "2         1  Adorable top with a hint of lace and a key hol...   \n",
       "3         1  New with tags. Leather horses. Retail for [rm]...   \n",
       "4         0          Complete with certificate of authenticity   \n",
       "\n",
       "                            stemmed_item_description clean_brand_name  \\\n",
       "0                                       descript yet      nobrandname   \n",
       "1  keyboard great condit work like came box port ...            razer   \n",
       "2  ador top hint lace key hole back pale pink als...           target   \n",
       "3  new tag leather hors retail rm stand foot high...      nobrandname   \n",
       "4                             complet certif authent      nobrandname   \n",
       "\n",
       "                  clean_category_name                   clean_item_name  \\\n",
       "0                             men top  mlb cincinnati red shirt size xl   \n",
       "1  electron comput tablet compon part  razer blackwidow chroma keyboard   \n",
       "2               women top blous blous                             blous   \n",
       "3   home home d cor home d cor accent                leather hors statu   \n",
       "4               women jewelri necklac                   gold plate rose   \n",
       "\n",
       "  assigned_category assigned_sub_category  \n",
       "0               Men                  Tops  \n",
       "1       Electronics                 Other  \n",
       "2             Women        Tops & blouses  \n",
       "3              Home                 Other  \n",
       "4             Women               Jewelry  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot-encoding Brand Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 569 brand names that occur >= 100 times in the dataset. Will one-hot-encode these brands only.\n"
     ]
    }
   ],
   "source": [
    "unique_brand_names = pd.DataFrame(clean_data.clean_brand_name.value_counts())\n",
    "min_brand_freq = 100\n",
    "print('There are', unique_brand_names[unique_brand_names['clean_brand_name']>=min_brand_freq].shape[0],\n",
    "      'brand names that occur >=',min_brand_freq, 'times in the dataset.','Will one-hot-encode these brands only.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1482486,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_brand_name_df = clean_data['clean_brand_name']\n",
    "clean_brand_name_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1482486, 4782)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_brand_name_df = pd.get_dummies(clean_brand_name_df)\n",
    "clean_brand_name_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1482486, 568)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_brand_col_lst = []\n",
    "keep_brand_col_lst = list(unique_brand_names[unique_brand_names['clean_brand_name']>=min_brand_freq].index.values)\n",
    "keep_brand_col_lst.remove('nobrandname')\n",
    "\n",
    "for col_name in clean_brand_name_df.columns:\n",
    "    if col_name not in keep_brand_col_lst:\n",
    "        drop_brand_col_lst.append(col_name)\n",
    "\n",
    "clean_brand_name_df_v2 =clean_brand_name_df.drop(columns=drop_brand_col_lst)\n",
    "clean_brand_name_df_v2.columns = ['brand_' + str(col) for col in clean_brand_name_df_v2.columns]\n",
    "clean_brand_name_df_v2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1482486, 579)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data_v2 = pd.concat([clean_data.reset_index(drop=True)\n",
    "                                   , clean_brand_name_df_v2.reset_index(drop=True)],\n",
    "                                  axis=1).drop(columns=['brand_name','clean_brand_name'])\n",
    "clean_data_v2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete the variables from memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del [[clean_brand_name_df,clean_brand_name_df_v2, clean_data]]\n",
    "gc.collect()\n",
    "clean_data = pd.DataFrame()\n",
    "clean_brand_name_df=pd.DataFrame()\n",
    "clean_brand_name_df_v2=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot-encoding Assigned Category and Assigned Sub Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1482486, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_category_name_df = clean_data_v2[['assigned_category', 'assigned_sub_category']]\n",
    "clean_category_name_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assigned_category</th>\n",
       "      <th>assigned_sub_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Men</td>\n",
       "      <td>Tops</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Electronics</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Women</td>\n",
       "      <td>Tops &amp; blouses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Home</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Women</td>\n",
       "      <td>Jewelry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  assigned_category assigned_sub_category\n",
       "0               Men                  Tops\n",
       "1       Electronics                 Other\n",
       "2             Women        Tops & blouses\n",
       "3              Home                 Other\n",
       "4             Women               Jewelry"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_category_name_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1482486, 119)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_category_name_df_v2 = pd.get_dummies(clean_category_name_df)\n",
    "clean_category_name_df_v2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1482486, 579)\n",
      "(1482486, 698)\n"
     ]
    }
   ],
   "source": [
    "# concat with main dataset on clean_category_name\n",
    "print(clean_data_v2.shape)\n",
    "clean_data_v3 = pd.concat([clean_data_v2, clean_category_name_df_v2], axis=1)\n",
    "print(clean_data_v3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete dataframes from memory\n",
    "del [[clean_category_name_df,clean_category_name_df_v2, clean_data_v2]]\n",
    "gc.collect()\n",
    "clean_data_v2 = pd.DataFrame()\n",
    "clean_category_name_df=pd.DataFrame()\n",
    "clean_category_name_df_v2=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encode item condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1482486, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_condition_df = clean_data_v3[['item_condition_id']]\n",
    "item_condition_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joashc/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "item_condition_df['item_condition_id'] = item_condition_df['item_condition_id'].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1482486, 5)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_condition_df_v2 = pd.get_dummies(item_condition_df)\n",
    "item_condition_df_v2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1482486, 698)\n",
      "(1482486, 703)\n",
      "CPU times: user 463 ms, sys: 298 ms, total: 761 ms\n",
      "Wall time: 788 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(clean_data_v3.shape)\n",
    "clean_data_v4 = pd.concat([clean_data_v3, item_condition_df_v2], axis=1)\n",
    "print(clean_data_v4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete dataframes from memory\n",
    "del [[item_condition_df,item_condition_df_v2, clean_data_v3]]\n",
    "gc.collect()\n",
    "clean_data_v3 = pd.DataFrame()\n",
    "item_condition_df_v2=pd.DataFrame()\n",
    "item_condition_df=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shipping\n",
    "- Change value of 0 to -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data_v4['shipping'] = clean_data_v4['shipping'].replace([0], [-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Unwanted Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1482486, 695)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data_v4 = clean_data_v4.drop(columns=['name', 'category_name', 'item_description', 'stemmed_item_description',\n",
    "       'clean_category_name', 'clean_item_name', 'assigned_category',\n",
    "       'assigned_sub_category'])\n",
    "clean_data_v4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in train and validation data: 1185988 (1185988, 1)\n",
      "Number of rows in test data: 296498 (296498, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(clean_data_v4.drop(columns=['price']).reset_index(drop=True), \n",
    "                                                    clean_data_v4[['price']].reset_index(drop=True), \n",
    "                                                                  test_size=0.1, random_state=42)\n",
    "print('Number of rows in train and validation data:', X_train.shape[0], y_train.shape)\n",
    "print('Number of rows in test data:', X_test.shape[0], y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joashc/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxScaler Complete\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "columns = X_train.columns\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=columns)\n",
    "print('MinMaxScaler Complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model architecture parameters\n",
    "n_stocks = 500\n",
    "n_neurons_1 = 1024\n",
    "n_neurons_2 = 512\n",
    "n_neurons_3 = 256\n",
    "n_neurons_4 = 128\n",
    "n_target = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in train and validation data: 948790 (948790, 1)\n",
      "Number of rows in validation data: 237198 (237198, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train.reset_index(drop=True), \n",
    "                                                    y_train.reset_index(drop=True), \n",
    "                                                                  test_size=0.1, random_state=42)\n",
    "print('Number of rows in train and validation data:', X_train.shape[0], y_train.shape)\n",
    "print('Number of rows in validation data:', X_val.shape[0], y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.002\n",
    "    drop = 0.5\n",
    "    epochs_drop = 20\n",
    "    lrate = initial_lrate * math.pow(drop,\n",
    "    math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 948790 samples, validate on 237198 samples\n",
      "Epoch 1/1\n",
      "948790/948790 [==============================] - 85s 90us/step - loss: 1556.0403 - mean_squared_error: 1556.0403 - val_loss: 1271.5243 - val_mean_squared_error: 1271.5243\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "batch_size = 2213\n",
    "\n",
    "all_val_predictions = pd.DataFrame()\n",
    "\n",
    "train_val_rmsle = []\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.8))\n",
    "\n",
    "model.add(Dense(264, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1))\n",
    "#     model.add(Activation('sigmoid'))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "\n",
    "model_hist = model.fit(X_train, y_train, validation_data=(X_val,y_val), \n",
    "                       batch_size=batch_size, epochs=num_epochs, verbose=1)\n",
    "\n",
    "# 1200813/1200813 [==============================] - 62s 52us/step - loss: 1482.9186 - val_loss: 1086.2720\n",
    "# Epoch 2/15\n",
    "# 1200813/1200813 [==============================] - 59s 49us/step - loss: 1094.8557 - val_loss: 1063.3914\n",
    "# Epoch 3/15\n",
    "# 1200813/1200813 [==============================] - 59s 49us/step - loss: 1088.3559 - val_loss: 1058.8141\n",
    "# Epoch 4/15\n",
    "# 1200813/1200813 [==============================] - 59s 49us/step - loss: 1084.5598 - val_loss: 1064.0263\n",
    "# Epoch 5/15\n",
    "# 1200813/1200813 [==============================] - 60s 50us/step - loss: 1083.5474 - val_loss: 1057.3300\n",
    "# Epoch 6/15\n",
    "# 1200813/1200813 [==============================] - 60s 50us/step - loss: 1081.2210 - val_loss: 1053.7492\n",
    "# Epoch 7/15\n",
    "# 1200813/1200813 [==============================] - 59s 49us/step - loss: 1080.9597 - val_loss: 1051.4364\n",
    "# Epoch 8/15\n",
    "# 1200813/1200813 [==============================] - 59s 49us/step - loss: 1079.8223 - val_loss: 1055.7563\n",
    "# Epoch 9/15\n",
    "# 1200813/1200813 [==============================] - 59s 49us/step - loss: 1078.7325 - val_loss: 1055.9923\n",
    "# Epoch 10/15\n",
    "# 1200813/1200813 [==============================] - 59s 49us/step - loss: 1076.4778 - val_loss: 1058.3496\n",
    "# Epoch 11/15\n",
    "# 1200813/1200813 [==============================] - 59s 49us/step - loss: 1076.6074 - val_loss: 1055.3251"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error is: 26.90506422754862\n",
      "Validation error is: 29.538023054786148\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'scaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-c0e908360678>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Validation error is:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test error is:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'scaler' is not defined"
     ]
    }
   ],
   "source": [
    "print('Train error is:', np.sqrt(mean_squared_error(y_train,model.predict(X_train))))\n",
    "\n",
    "print('Validation error is:', np.sqrt(mean_squared_error(y_val,model.predict(X_val))))\n",
    "\n",
    "print('Test error is:', np.sqrt(mean_squared_error(y_test,model.predict(scaler.transform(X_test)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "batch_size = 2213\n",
    "\n",
    "all_val_predictions = pd.DataFrame()\n",
    "\n",
    "train_val_rmsle = []\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.8))\n",
    "\n",
    "model.add(Dense(264, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1))\n",
    "#     model.add(Activation('sigmoid'))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# num_epochs = 15\n",
    "# batch_size = 2213\n",
    "# Brand frequency: 100\n",
    "# lr: 0.002\n",
    "# test/train split: 0.1\n",
    "# test/val split: 0.1\n",
    "\n",
    "# 1200813/1200813 [==============================] - 62s 52us/step - loss: 1482.9186 - val_loss: 1086.2720\n",
    "# Epoch 2/15\n",
    "# 1200813/1200813 [==============================] - 59s 49us/step - loss: 1094.8557 - val_loss: 1063.3914\n",
    "# Epoch 3/15\n",
    "# 1200813/1200813 [==============================] - 59s 49us/step - loss: 1088.3559 - val_loss: 1058.8141\n",
    "# Epoch 4/15\n",
    "# 1200813/1200813 [==============================] - 59s 49us/step - loss: 1084.5598 - val_loss: 1064.0263\n",
    "# Epoch 5/15\n",
    "# 1200813/1200813 [==============================] - 60s 50us/step - loss: 1083.5474 - val_loss: 1057.3300\n",
    "# Epoch 6/15\n",
    "# 1200813/1200813 [==============================] - 60s 50us/step - loss: 1081.2210 - val_loss: 1053.7492\n",
    "# Epoch 7/15\n",
    "# 1200813/1200813 [==============================] - 59s 49us/step - loss: 1080.9597 - val_loss: 1051.4364\n",
    "# Epoch 8/15\n",
    "# 1200813/1200813 [==============================] - 59s 49us/step - loss: 1079.8223 - val_loss: 1055.7563\n",
    "# Epoch 9/15\n",
    "# 1200813/1200813 [==============================] - 59s 49us/step - loss: 1078.7325 - val_loss: 1055.9923\n",
    "# Epoch 10/15\n",
    "# 1200813/1200813 [==============================] - 59s 49us/step - loss: 1076.4778 - val_loss: 1058.3496\n",
    "# Epoch 11/15\n",
    "# 1200813/1200813 [==============================] - 59s 49us/step - loss: 1076.6074 - val_loss: 1055.3251\n",
    "\n",
    "- deleted it early because there was no improvement"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
